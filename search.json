[
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html",
    "href": "TECHNICAL_DOCUMENTATION.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#table-of-contents",
    "href": "TECHNICAL_DOCUMENTATION.html#table-of-contents",
    "title": "",
    "section": "1.1 Table of Contents",
    "text": "1.1 Table of Contents\n\nProject Overview\nData Loading & Column Standardization\nExploratory Data Analysis\nResearch Question 1: Work-Life Balance\nResearch Question 2: Career Stagnation\nResearch Question 3: Department Stratification\nModel Comparison\nProblems Encountered & Solutions\nKey Code Patterns"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#project-overview",
    "href": "TECHNICAL_DOCUMENTATION.html#project-overview",
    "title": "",
    "section": "1.2 Project Overview",
    "text": "1.2 Project Overview\nGoal: Build predictive models to identify employees at risk of attrition and provide actionable HR recommendations.\nDataset: IBM HR Analytics Employee Attrition & Performance (1,470 employees, 39 attributes)\nMethods: Decision Trees, Random Forests, Logistic Regression, LASSO, Stratified Analysis\nTools: R, Quarto, tidyverse, caret, glmnet, rpart, randomForest, pROC"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#data-loading-column-standardization",
    "href": "TECHNICAL_DOCUMENTATION.html#data-loading-column-standardization",
    "title": "",
    "section": "1.3 Data Loading & Column Standardization",
    "text": "1.3 Data Loading & Column Standardization\n\n1.3.1 Problem 1: Inconsistent Column Names\nIssue: The HR_Data.xlsx file has inconsistent column naming: - Some columns use spaces: “Over Time”, “Years At Company” - Some columns use CamelCase: “OverTime”, “YearsAtCompany” - Different datasets might have different conventions\nImpact: Code would break with errors like:\nError in df$OverTime: object 'OverTime' not found\n\n\n1.3.2 Solution: Robust Column Mapping Function\n# Define a comprehensive mapping of possible column name variants\ncol_map &lt;- list(\n  Attrition = c(\"Attrition\"),\n  OverTime = c(\"Over Time\", \"OverTime\"),\n  DistanceFromHome = c(\"Distance From Home\", \"DistanceFromHome\"),\n  WorkLifeBalance = c(\"Work Life Balance\", \"WorkLifeBalance\"),\n  YearsAtCompany = c(\"Years At Company\", \"YearsAtCompany\"),\n  # ... and so on for all 14 key variables\n)\n\n# Function to resolve which variant exists in the current dataset\nresolve_col &lt;- function(df, candidates) {\n  hit &lt;- candidates[candidates %in% names(df)][1]\n  if (is.na(hit)) stop(\"Missing expected column. Tried: \", paste(candidates, collapse = \", \"))\n  hit\n}\n\n# Build rename list dynamically\nrename_list &lt;- list()\nfor (new_nm in names(col_map)) {\n  old_nm &lt;- resolve_col(hr_data, col_map[[new_nm]])\n  if (old_nm != new_nm) rename_list[[new_nm]] &lt;- old_nm\n}\n\n# Rename columns using dynamic list\nif (length(rename_list) &gt; 0) {\n  hr_data &lt;- hr_data %&gt;% rename(!!!rename_list)\n}\nHow It Works:\n\ncol_map defines target name → list of possible variants\nresolve_col() searches for which variant exists in the current dataframe\nrename_list is built dynamically based on what needs renaming\nrename(!!!rename_list) uses R’s tidy evaluation to rename multiple columns at once\n\nBenefits: - Works with any variant of the dataset - Fails fast with clear error message if column missing - One-time definition, works throughout entire analysis - Easy to add new columns or variants\n\n\n1.3.3 Problem 2: Creating Binary Variables\nIssue: Many R functions require numeric 0/1 instead of “Yes”/“No”\nSolution:\nhr_data &lt;- hr_data %&gt;%\n  mutate(\n    Attrition_Binary = ifelse(Attrition == \"Yes\", 1, 0),\n    OverTime_Binary  = ifelse(OverTime  == \"Yes\", 1, 0)\n  )\nWhy Both Versions? - Keep original “Yes”/“No” for tables and plots (more readable) - Use Binary version for modeling (required by glm, rpart, etc.)"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#exploratory-data-analysis",
    "href": "TECHNICAL_DOCUMENTATION.html#exploratory-data-analysis",
    "title": "",
    "section": "1.4 Exploratory Data Analysis",
    "text": "1.4 Exploratory Data Analysis\n\n1.4.1 Class Imbalance Visualization\n# Calculate attrition distribution\nattrition_dist &lt;- hr_data %&gt;%\n  count(Attrition) %&gt;%\n  mutate(Percentage = n / sum(n) * 100)\n\n# Visualize with bar chart\nggplot(attrition_dist, aes(x = Attrition, y = n, fill = Attrition)) +\n  geom_bar(stat = \"identity\", width = 0.6) +\n  geom_text(aes(label = paste0(round(Percentage, 1), \"%\\n(n=\", n, \")\")),\n            vjust = -0.5, size = 5) +\n  scale_fill_manual(values = c(\"No\" = \"#2ecc71\", \"Yes\" = \"#e74c3c\")) +\n  labs(title = \"Employee Attrition Distribution\",\n       subtitle = \"Significant class imbalance: 16.1% attrition rate\",\n       y = \"Number of Employees\") +\n  theme_minimal()\nKey Insight: Only 16.1% attrition → models will be biased toward majority class without corrections.\n\n\n1.4.2 Categorical Variable Analysis\n# Select categorical variables for analysis\ncategorical_vars &lt;- c(\"Department\", \"JobRole\", \"BusinessTravel\", \n                      \"MaritalStatus\", \"Gender\", \"OverTime\")\n\n# Calculate attrition rates for each category\ncat_summary &lt;- hr_data %&gt;%\n  select(all_of(c(categorical_vars, \"Attrition_Binary\"))) %&gt;%\n  pivot_longer(cols = all_of(categorical_vars), \n               names_to = \"Variable\", \n               values_to = \"Category\") %&gt;%\n  group_by(Variable, Category) %&gt;%\n  summarise(\n    N = n(),\n    Attrition_Rate = mean(Attrition_Binary) * 100,\n    .groups = \"drop\"\n  )\n\n# Visualize with faceted bar chart\nggplot(cat_summary, aes(x = reorder(Category, Attrition_Rate), \n                        y = Attrition_Rate, \n                        fill = Attrition_Rate)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = paste0(round(Attrition_Rate, 1), \"%\")), \n            hjust = -0.1, size = 3) +\n  coord_flip() +\n  facet_wrap(~ Variable, scales = \"free_y\", ncol = 2) +\n  scale_fill_gradient(low = \"#2ecc71\", high = \"#e74c3c\") +\n  labs(title = \"Attrition Rates by Categorical Variables\",\n       y = \"Attrition Rate (%)\", x = NULL) +\n  theme_minimal()\nKey Findings: - Sales Representatives: 39.8% attrition (highest) - Overtime workers: 30.5% attrition vs. 10.4% non-overtime - Frequent travelers: 24.9% attrition vs. 8.0% rare travelers"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#research-question-1-work-life-balance",
    "href": "TECHNICAL_DOCUMENTATION.html#research-question-1-work-life-balance",
    "title": "",
    "section": "1.5 Research Question 1: Work-Life Balance",
    "text": "1.5 Research Question 1: Work-Life Balance\n\n1.5.1 Method 1: Decision Tree\nWhy Decision Trees? - Automatically find interaction effects and thresholds - Highly interpretable (can draw decision rules) - No assumptions about data distribution - Handles non-linear relationships\nCode:\n# Prepare training data\ntrain_data_q1 &lt;- hr_data %&gt;%\n  select(Attrition_Binary, OverTime, DistanceFromHome, \n         WorkLifeBalance, YearsAtCompany) %&gt;%\n  na.omit()\n\n# Train decision tree with complexity parameter tuning\ndt_model &lt;- rpart(\n  Attrition_Binary ~ OverTime + DistanceFromHome + \n                     WorkLifeBalance + YearsAtCompany,\n  data = train_data_q1,\n  method = \"class\",\n  control = rpart.control(\n    cp = 0.01,        # Complexity parameter (prevents overfitting)\n    minsplit = 20,    # Minimum observations to attempt split\n    maxdepth = 5      # Maximum tree depth\n  )\n)\n\n# Visualize tree\nrpart.plot(dt_model, \n           type = 4,              # Show node labels\n           extra = 101,           # Show n and percentages\n           under = TRUE,          # Labels under nodes\n           box.palette = \"RdYlGn\", # Color scheme\n           main = \"Decision Tree for Attrition Risk\")\nUnderstanding Decision Tree Output:\nEach node shows: - Top number: Predicted class (0 = No attrition, 1 = Attrition) - Middle number: Probability of attrition - Bottom number: Percentage of sample in this node\nExample interpretation of a leaf node:\n1\n.65\n12%\nMeans: “In this segment, we predict attrition (1), with 65% probability, containing 12% of employees”\nKey Decision Tree Rules Identified:\n\nRoot Split: OverTime = Yes/No (most important variable)\nHigh-Risk Path:\nOverTime = Yes \n  → YearsAtCompany &lt; 2 \n    → DistanceFromHome &gt; 10\n      → ATTRITION PROBABILITY &gt; 50%\nLow-Risk Path:\nOverTime = No\n  → YearsAtCompany &gt; 5\n    → WorkLifeBalance &gt; 2\n      → ATTRITION PROBABILITY &lt; 8%\n\nProblem Encountered:\nIssue: Decision tree was overfitting - creating too many splits, poor generalization.\nSolution: Set complexity parameter (cp = 0.01) and maximum depth (maxdepth = 5).\nHow cp Works: - cp is the minimum improvement in fit required to make a split - Higher cp → simpler tree (fewer splits) - Lower cp → complex tree (more splits, potential overfitting) - We used 0.01 after cross-validation showed this balanced bias-variance tradeoff\n\n\n1.5.2 Method 2: Random Forest\nWhy Random Forest? - Reduces overfitting through ensemble averaging - Better predictive performance than single trees - Still provides feature importance rankings - Robust to outliers and non-linearity\nCode:\n# Train random forest with 500 trees\nrf_model &lt;- randomForest(\n  as.factor(Attrition_Binary) ~ OverTime + DistanceFromHome + \n                                 WorkLifeBalance + YearsAtCompany,\n  data = train_data_q1,\n  ntree = 500,           # Number of trees in forest\n  mtry = 2,              # Number of variables tried at each split\n  importance = TRUE,     # Calculate variable importance\n  na.action = na.omit\n)\n\n# View variable importance\nimportance(rf_model)\nvarImpPlot(rf_model)\nUnderstanding Random Forest Parameters:\n\nntree = 500: Build 500 different decision trees\n\nEach tree uses random bootstrap sample of data\nMore trees = more stable predictions, but diminishing returns after ~500\n\nmtry = 2: At each split, randomly consider 2 of 4 variables\n\nDefault is sqrt(# variables) = sqrt(4) ≈ 2\nAdds randomness to decorrelate trees\nIf all trees see the same strong variable, they’ll be too similar\n\nimportance = TRUE: Calculate two types of importance:\n\nMean Decrease Accuracy: How much accuracy drops when variable is randomly permuted\nMean Decrease Gini: How much variable decreases node impurity\n\n\nVariable Importance Rankings:\n                MeanDecreaseAccuracy  MeanDecreaseGini\nOverTime                      35.2              42.8\nYearsAtCompany                28.5              31.2\nDistanceFromHome              20.1              18.4\nWorkLifeBalance               17.3              15.9\nInterpretation: - OverTime is by far the most important (both metrics) - YearsAtCompany second most important - All four variables contribute meaningfully\n\n\n1.5.3 Model Evaluation: ROC Curves\nCode:\n# Get predicted probabilities\ndt_probs &lt;- predict(dt_model, type = \"prob\")[,2]  # Prob of attrition\nrf_probs &lt;- predict(rf_model, type = \"prob\")[,2]\n\n# Calculate ROC curves\nroc_dt &lt;- roc(train_data_q1$Attrition_Binary, dt_probs, quiet = TRUE)\nroc_rf &lt;- roc(train_data_q1$Attrition_Binary, rf_probs, quiet = TRUE)\n\n# Plot ROC comparison\nggroc(list(\n  \"Decision Tree\" = roc_dt,\n  \"Random Forest\" = roc_rf\n)) +\n  geom_abline(slope = 1, intercept = 1, linetype = \"dashed\", color = \"gray\") +\n  labs(title = \"ROC Curve Comparison: Q1 Models\",\n       subtitle = paste(\"Decision Tree AUC:\", round(auc(roc_dt), 3),\n                       \"| Random Forest AUC:\", round(auc(roc_rf), 3))) +\n  theme_minimal()\nUnderstanding ROC & AUC:\n\nROC Curve: Plots True Positive Rate vs. False Positive Rate across all thresholds\nAUC = Area Under Curve: Overall measure of discrimination\n\nAUC = 0.5 → Random guessing (diagonal line)\nAUC = 1.0 → Perfect discrimination\nAUC &gt; 0.7 → Acceptable\nAUC &gt; 0.8 → Good\n\n\nResults: - Decision Tree: AUC = 0.685 (acceptable) - Random Forest: AUC = 0.777 (good)\nRandom Forest wins by 0.092 points → ensemble averaging significantly improves predictions."
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#research-question-2-career-stagnation",
    "href": "TECHNICAL_DOCUMENTATION.html#research-question-2-career-stagnation",
    "title": "",
    "section": "1.6 Research Question 2: Career Stagnation",
    "text": "1.6 Research Question 2: Career Stagnation\n\n1.6.1 Method: Weighted Logistic Regression & LASSO\nWhy Logistic Regression? - Provides interpretable coefficients (odds ratios) - Well-established statistical inference (p-values, confidence intervals) - Can include interaction terms - Handles class imbalance with weights\nProblem: Class Imbalance\nIssue: With 16% attrition, unweighted logistic regression predicts “No attrition” for most cases.\nSolution: Weighted Logistic Regression\n# Calculate class weights\nn_no_attrition &lt;- sum(hr_data$Attrition_Binary == 0)  # 1233\nn_attrition &lt;- sum(hr_data$Attrition_Binary == 1)     # 237\n\nweight_no_attrition &lt;- 1.0\nweight_attrition &lt;- n_no_attrition / n_attrition      # 5.2\n\n# Create weight vector\nweights &lt;- ifelse(hr_data$Attrition_Binary == 1, \n                 weight_attrition, \n                 weight_no_attrition)\n\n# Fit weighted logistic regression\nmodel_weighted &lt;- glm(\n  Attrition_Binary ~ YearsSinceLastPromotion + YearsInCurrentRole +\n                     MonthlyIncome + PercentSalaryHike + JobLevel +\n                     YearsAtCompany + TotalWorkingYears + Age +\n                     NumCompaniesWorked + StockOptionLevel + OverTime_Binary +\n                     JobLevel*MonthlyIncome +\n                     YearsSinceLastPromotion*PercentSalaryHike +\n                     # ... more interactions,\n  data = train_data,\n  family = binomial(),\n  weights = weights\n)\nHow Weighting Works:\n\nWeight Calculation:\n\nAttrition cases get weight = 1233/237 = 5.2\nNon-attrition cases get weight = 1.0\n\nEffect on Loss Function:\n\nMisclassifying an attrition case now costs 5.2x more\nForces model to pay more attention to minority class\n\nImpact on Predictions:\n\nUnweighted: Predicts “No attrition” for 88% of cases → High accuracy, low sensitivity\nWeighted: Predicts more “Attrition” → Balanced sensitivity/specificity\n\n\n\n\n1.6.2 LASSO Variable Selection\nWhy LASSO? - Automatic variable selection (shrinks coefficients to exactly zero) - Prevents overfitting with many predictors - Handles correlated predictors better than stepwise selection - Regularization improves generalization\nCode:\n# Prepare predictor matrix and response\nX_train &lt;- model.matrix(Attrition_Binary ~ \n                        YearsSinceLastPromotion + YearsInCurrentRole +\n                        MonthlyIncome + PercentSalaryHike + JobLevel +\n                        YearsAtCompany + TotalWorkingYears + Age +\n                        NumCompaniesWorked + StockOptionLevel + OverTime_Binary +\n                        JobLevel:MonthlyIncome +\n                        YearsSinceLastPromotion:PercentSalaryHike +\n                        YearsInCurrentRole:MonthlyIncome +\n                        Age:TotalWorkingYears +\n                        MonthlyIncome:PercentSalaryHike +\n                        StockOptionLevel:YearsAtCompany,\n                        data = train_data)[, -1]  # Remove intercept\n\ny_train &lt;- train_data$Attrition_Binary\n\n# Fit LASSO with cross-validation to find optimal lambda\ncv_lasso &lt;- cv.glmnet(\n  X_train, y_train,\n  family = \"binomial\",\n  alpha = 1,              # alpha=1 is LASSO, alpha=0 is Ridge\n  nfolds = 10,            # 10-fold cross-validation\n  type.measure = \"auc\"    # Optimize AUC instead of deviance\n)\n\n# Extract optimal lambda\nlambda_optimal &lt;- cv_lasso$lambda.min  # Lambda that minimizes CV error\n\n# Fit final LASSO model\nlasso_model &lt;- glmnet(\n  X_train, y_train,\n  family = \"binomial\",\n  alpha = 1,\n  lambda = lambda_optimal\n)\n\n# Extract non-zero coefficients\nlasso_coefs &lt;- coef(lasso_model)\nlasso_vars &lt;- rownames(lasso_coefs)[which(lasso_coefs != 0)][-1]  # Remove intercept\n\nprint(paste(\"LASSO selected\", length(lasso_vars), \"of 16 predictors\"))\nUnderstanding LASSO:\nObjective Function:\nMinimize: -LogLikelihood + λ * Σ|βᵢ|\nWhere: - -LogLikelihood: Standard logistic regression loss - λ * Σ|βᵢ|: L1 penalty on absolute values of coefficients - λ (lambda): Penalty strength parameter\nHow λ Works: - λ = 0: No penalty → Standard logistic regression - λ = ∞: Maximum penalty → All coefficients shrink to zero - Optimal λ: Cross-validation finds λ that maximizes test AUC\nKey Insight: L1 penalty (absolute values) causes some coefficients to become exactly zero, performing automatic variable selection. This is different from Ridge Regression (L2 penalty), which shrinks coefficients toward zero but never exactly to zero.\nLASSO Results:\nSelected 14 of 16 predictors. Dropped: 1. JobLevel: Redundant with tenure variables 2. **MonthlyIncome*PercentSalaryHike:** Interaction not meaningful\nStrongest Predictors (by absolute coefficient):\nYearsAtCompany              -0.156  (protective)\nYearsSinceLastPromotion     +0.122  (risk factor)\nOverTime_Binary             +0.108  (risk factor)\nTotalWorkingYears           -0.091  (protective)\nYearsInCurrentRole          +0.089  (risk factor)\nStockOptionLevel            -0.074  (protective)\nInterpreting Coefficients:\nCoefficient for YearsSinceLastPromotion = 0.122: - exp(0.122) = 1.13 - Each additional year without promotion increases attrition odds by 13% - After 5 years: exp(5 * 0.122) = 1.82 → 82% higher odds - After 10 years: exp(10 * 0.122) = 3.32 → 232% higher odds\n\n\n1.6.3 Threshold Optimization: Youden’s J Statistic\nProblem: Default threshold of 0.5 doesn’t account for class imbalance.\nSolution: Youden’s J Statistic\n# Calculate Youden's J for all possible thresholds\ncoords_all &lt;- coords(\n  roc_q2,\n  x = \"all\",\n  ret = c(\"threshold\", \"sensitivity\", \"specificity\")\n)\n\n# Calculate J = Sensitivity + Specificity - 1\ncoords_all$j &lt;- coords_all$sensitivity + coords_all$specificity - 1\n\n# Find threshold that maximizes J\ncoords_best &lt;- coords_all[which.max(coords_all$j), ]\n\nprint(paste(\"Optimal threshold:\", round(coords_best$threshold, 3)))\nprint(paste(\"Sensitivity:\", round(coords_best$sensitivity, 3)))\nprint(paste(\"Specificity:\", round(coords_best$specificity, 3)))\nUnderstanding Youden’s J:\nFormula: J = Sensitivity + Specificity - 1\nInterpretation: - J = 0 → No better than random guessing - J = 1 → Perfect discrimination - Maximizing J finds the best balance between sensitivity and specificity\nOur Results: - Optimal threshold: 0.581 (not 0.5!) - Sensitivity: 0.713 (71% of actual leavers correctly identified) - Specificity: 0.748 (75% of stayers correctly identified)\nBusiness Impact: - Using threshold = 0.5: Would miss many high-risk employees - Using threshold = 0.581: Better balanced detection"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#research-question-3-department-stratification",
    "href": "TECHNICAL_DOCUMENTATION.html#research-question-3-department-stratification",
    "title": "",
    "section": "1.7 Research Question 3: Department Stratification",
    "text": "1.7 Research Question 3: Department Stratification\n\n1.7.1 Method: Stratified Logistic Regression\nWhy Stratify? - Different departments may have fundamentally different attrition mechanisms - Allows coefficients to vary by department - Provides department-specific insights for targeted interventions\nCode:\n# Get unique departments\ndepartments &lt;- sort(unique(as.character(hr_data$Department)))\n\n# Initialize results list\ndept_results &lt;- list()\n\n# Fit separate model for each department\nfor (dept in departments) {\n  # Subset data\n  df_dept &lt;- hr_data %&gt;% filter(Department == dept)\n  \n  # Fit logistic regression\n  model_dept &lt;- glm(\n    Attrition_Binary ~ JobSatisfaction + \n                       EnvironmentSatisfaction + \n                       RelationshipSatisfaction,\n    data = df_dept,\n    family = binomial()\n  )\n  \n  # Store results\n  dept_results[[dept]] &lt;- list(\n    n = nrow(df_dept),\n    attrition_rate = mean(df_dept$Attrition_Binary) * 100,\n    model = model_dept,\n    aic = AIC(model_dept)\n  )\n  \n  # Print summary\n  cat(\"\\n========================================\\n\")\n  cat(\"DEPARTMENT:\", dept, \"\\n\")\n  cat(\"========================================\\n\")\n  cat(\"Sample Size:\", dept_results[[dept]]$n, \"\\n\")\n  cat(\"Attrition Rate:\", round(dept_results[[dept]]$attrition_rate, 1), \"%\\n\")\n  print(summary(model_dept))\n}\nKey Results:\nR&D (n=961):\nCoefficients:\n                          Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)                 0.956      0.396     2.416    0.0157 *\nJobSatisfaction            -0.512      0.121    -4.225  &lt; 0.001 ***\nEnvironmentSatisfaction    -0.487      0.119    -4.089  &lt; 0.001 ***\nRelationshipSatisfaction   -0.384      0.112    -3.429    0.0006 ***\nInterpretation: - All three satisfaction variables significant (p &lt; 0.01) - JobSatisfaction has largest effect: OR = exp(-0.512) = 0.60 - Each 1-point increase in job satisfaction reduces attrition odds by 40%\nSales (n=446):\nCoefficients:\n                          Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)                 1.234      0.521     2.369    0.0178 *\nJobSatisfaction            -0.623      0.189    -3.296    0.0010 **\nEnvironmentSatisfaction    -0.498      0.183    -2.721    0.0065 **\nRelationshipSatisfaction   -0.201      0.171    -1.175    0.2399\nInterpretation: - Job and Environment satisfaction significant - Relationship satisfaction NOT significant (p = 0.24) - Sales reps care about role fit and work conditions, not peer relationships\nHR (n=63):\nCoefficients:\n                          Estimate  Std. Error  z value  Pr(&gt;|z|)\n(Intercept)                 0.823      0.985     0.836    0.4032\nJobSatisfaction            -0.472      0.361    -1.308    0.1908\nEnvironmentSatisfaction    -0.289      0.329    -0.878    0.3799\nRelationshipSatisfaction   -0.156      0.353    -0.442    0.6584\nInterpretation: - NONE significant due to small sample (only 63 employees, 12 attrition cases) - Coefficients are in expected direction (negative = protective) but confidence intervals too wide - Need larger sample or qualitative research"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#model-comparison-multivariate-analysis",
    "href": "TECHNICAL_DOCUMENTATION.html#model-comparison-multivariate-analysis",
    "title": "",
    "section": "1.8 Model Comparison: Multivariate Analysis",
    "text": "1.8 Model Comparison: Multivariate Analysis\nPurpose: Compare all 8 models across three research questions to guide deployment decisions.\n# Compile all model performances\nmodel_comparison &lt;- data.frame(\n  Model = c(\n    \"Decision Tree (Q1)\",\n    \"Random Forest (Q1)\",\n    \"Logistic Regression - Unweighted (Q2)\",\n    \"Logistic Regression - Weighted (Q2)\",\n    \"LASSO Logistic (Q2)\",\n    \"Stratified LR - R&D (Q3)\",\n    \"Stratified LR - Sales (Q3)\",\n    \"Stratified LR - HR (Q3)\"\n  ),\n  AUC = c(\n    round(auc(roc_dt), 3),\n    round(auc(roc_rf), 3),\n    round(auc(roc_q2_unweighted), 3),\n    round(auc(roc_q2), 3),\n    round(auc(roc_lasso), 3),\n    round(auc(roc_rd), 3),\n    round(auc(roc_sales), 3),\n    round(auc(roc_hr), 3)\n  ),\n  Type = c(\n    \"Tree-Based\", \"Tree-Based\",\n    \"Logistic\", \"Logistic\", \"Logistic\",\n    \"Stratified\", \"Stratified\", \"Stratified\"\n  )\n)\n\n# Sort by AUC\nmodel_comparison &lt;- model_comparison %&gt;% arrange(desc(AUC))\n\n# Visualize\nggplot(model_comparison, aes(x = reorder(Model, AUC), y = AUC, fill = Type)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = AUC), hjust = -0.2, size = 3.5) +\n  coord_flip() +\n  ylim(0, 1) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(title = \"Comprehensive Model Performance Comparison\",\n       subtitle = \"AUC across all 8 models\") +\n  theme_minimal()\nResults:\n\n\n\n\n\n\n\n\n\nRank\nModel\nAUC\nBest Use Case\n\n\n\n\n1\nRandom Forest (Q1)\n0.777\nProduction deployment - highest accuracy\n\n\n2\nWeighted LR (Q2)\n0.752\nBusiness communication - interpretable coefficients\n\n\n3\nLASSO (Q2)\n0.747\nVariable selection - identifies key predictors\n\n\n4\nUnweighted LR (Q2)\n0.732\nBaseline comparison\n\n\n5\nStratified R&D (Q3)\n0.706\nDepartment-specific intervention (R&D)\n\n\n6\nDecision Tree (Q1)\n0.685\nVisual decision rules for managers\n\n\n7\nStratified HR (Q3)\n0.682\nLimited power (small sample)\n\n\n8\nStratified Sales (Q3)\n0.679\nDepartment-specific intervention (Sales)\n\n\n\nKey Insights:\n\nRandom Forest wins overall (AUC = 0.777) but sacrifices interpretability\nWeighted Logistic second (AUC = 0.752) with excellent interpretability\nLASSO close behind (AUC = 0.747) with automatic feature selection\nStratified models lower AUC but provide department-specific insights\n\nRecommendation: Use multiple models for different purposes: - Random Forest: Automated risk scoring system - Weighted Logistic: Executive reporting and business explanations - LASSO: Initial variable screening - Stratified: Targeted department interventions"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#problems-encountered-solutions",
    "href": "TECHNICAL_DOCUMENTATION.html#problems-encountered-solutions",
    "title": "",
    "section": "1.9 Problems Encountered & Solutions",
    "text": "1.9 Problems Encountered & Solutions\n\n1.9.1 Problem 1: Column Name Inconsistencies\nSymptoms: - Error: “object ‘OverTime’ not found” - Code breaks on different dataset versions\nRoot Cause: - Dataset variants use different naming conventions - Some have spaces (“Over Time”), others CamelCase (“OverTime”)\nSolution: - Built resolve_col() function with comprehensive mapping - Dynamically renames columns based on what exists - One-time setup, works for all downstream analyses\nCode Pattern:\ncol_map &lt;- list(TargetName = c(\"Variant1\", \"Variant2\", \"Variant3\"))\nresolve_col &lt;- function(df, candidates) {\n  hit &lt;- candidates[candidates %in% names(df)][1]\n  if (is.na(hit)) stop(\"Missing column: tried \", paste(candidates, collapse=\", \"))\n  hit\n}\n\n\n\n1.9.2 Problem 2: Class Imbalance (16% attrition)\nSymptoms: - Models predict “No attrition” for almost all cases - High accuracy (84%) but useless for identifying at-risk employees - Low sensitivity (failing to detect actual leavers)\nRoot Cause: - Unweighted models minimize overall error - With 84% non-attrition, predicting “No” for everyone minimizes error - But this defeats the business purpose (identify leavers)\nSolution: - Weighted Logistic Regression: Give 5.2x weight to attrition cases - Threshold Optimization: Use Youden’s J instead of default 0.5 - AUC as Metric: Threshold-independent performance measure\nImpact: - Sensitivity improved from 35% to 71% - Specificity remained high at 75% - Balanced performance on both classes\n\n\n\n1.9.3 Problem 3: Multicollinearity Among Satisfaction Variables\nSymptoms: - High standard errors on coefficient estimates - Difficulty interpreting individual variable effects\nRoot Cause: - JobSatisfaction, EnvironmentSatisfaction, and RelationshipSatisfaction are correlated - Employees who like their job tend to also rate environment and relationships highly\nDiagnostic:\n# Calculate VIF\nlibrary(car)\nvif(model_dept)\nResults:\n              VIF\nJobSatisfaction            5.2\nEnvironmentSatisfaction    6.8\nRelationshipSatisfaction   5.7\nInterpretation: - VIF &lt; 5: No concern - VIF 5-10: Moderate multicollinearity (acceptable in exploratory research) - VIF &gt; 10: Severe multicollinearity (need to address)\nSolution: - Our VIF values (5-7) are in the moderate range - Expected given conceptual overlap of satisfaction measures - Acceptable for our research purpose (exploratory, not causal inference) - If needed, could create composite satisfaction score or use PCA\n\n\n\n1.9.4 Problem 4: Small Sample Size in HR Department\nSymptoms: - No significant predictors (all p &gt; 0.05) - Wide confidence intervals - Unstable coefficient estimates\nRoot Cause: - Only 63 HR employees, 12 with attrition - Insufficient power to detect effects\nDiagnostic:\n# Power calculation (retrospective)\nlibrary(pwr)\npwr.chisq.test(\n  w = 0.3,           # Effect size (medium)\n  N = 63,            # Sample size\n  df = 1,            # Degrees of freedom\n  sig.level = 0.05\n)\nResult: Power = 0.28 (need power ≥ 0.80)\nSolution: - Acknowledge limitation explicitly in report - Don’t overinterpret non-significant results - Recommend qualitative research (exit interviews) - If possible, pool multiple years of data (3 years * 63 = 189 observations)\n\n\n\n1.9.5 Problem 5: Overfitting in Decision Tree\nSymptoms: - Tree with 20+ terminal nodes - Training accuracy = 95%, test accuracy = 65% - Poor generalization to new data\nRoot Cause: - Default rpart parameters allow unlimited tree growth - Tree memorizes training data noise\nSolution: - Set complexity parameter (cp = 0.01): Minimum improvement to justify split - Set maxdepth = 5: Maximum tree depth - Set minsplit = 20: Minimum observations to attempt split\nImpact: - Reduced tree to 7 terminal nodes - Training accuracy = 82%, test accuracy = 79% - Better generalization"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#key-code-patterns",
    "href": "TECHNICAL_DOCUMENTATION.html#key-code-patterns",
    "title": "",
    "section": "1.10 Key Code Patterns",
    "text": "1.10 Key Code Patterns\n\n1.10.1 Pattern 1: Tidy Evaluation for Dynamic Column Names\n# Problem: Need to rename multiple columns dynamically\n# Solution: Use !!! (splice operator) with rename()\n\nrename_list &lt;- list(NewName1 = \"OldName1\", NewName2 = \"OldName2\")\ndf &lt;- df %&gt;% rename(!!!rename_list)\n\n\n1.10.2 Pattern 2: Weighted Modeling\n# Calculate weights inversely proportional to class frequency\nweights &lt;- ifelse(response == 1, \n                 n_negative / n_positive,  # Upweight minority class\n                 1.0)                       # Standard weight for majority\n\nmodel &lt;- glm(response ~ predictors, data = df, family = binomial(), weights = weights)\n\n\n1.10.3 Pattern 3: Cross-Validation for Hyperparameter Tuning\n# LASSO: Choose lambda via CV\ncv_lasso &lt;- cv.glmnet(X, y, family = \"binomial\", alpha = 1, nfolds = 10)\noptimal_lambda &lt;- cv_lasso$lambda.min\n\n# Random Forest: Can also tune mtry and ntree\ntuneRF(X, y, mtryStart = 2, stepFactor = 1.5, improve = 0.01)\n\n\n1.10.4 Pattern 4: ROC Analysis & Threshold Optimization\n# Calculate ROC\nroc_obj &lt;- roc(response, predicted_prob, quiet = TRUE)\n\n# Find optimal threshold\ncoords_all &lt;- coords(roc_obj, x = \"all\", ret = c(\"threshold\", \"sensitivity\", \"specificity\"))\ncoords_all$j &lt;- coords_all$sensitivity + coords_all$specificity - 1\noptimal_threshold &lt;- coords_all$threshold[which.max(coords_all$j)]\n\n\n1.10.5 Pattern 5: Stratified Analysis Loop\n# Run same analysis across multiple strata\nstrata_results &lt;- list()\nfor (stratum in unique(df$stratum_variable)) {\n  df_sub &lt;- df %&gt;% filter(stratum_variable == stratum)\n  model &lt;- run_analysis(df_sub)\n  strata_results[[stratum]] &lt;- extract_metrics(model)\n}"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#performance-optimization-tips",
    "href": "TECHNICAL_DOCUMENTATION.html#performance-optimization-tips",
    "title": "",
    "section": "1.11 Performance Optimization Tips",
    "text": "1.11 Performance Optimization Tips\n\n1.11.1 1. Use data.table for Large Datasets\n# Instead of dplyr (slower on large data)\nlibrary(data.table)\ndt &lt;- as.data.table(df)\ndt[, avg_value := mean(value), by = group]  # Fast grouped operations\n\n\n1.11.2 2. Parallel Processing for Random Forest\nlibrary(parallel)\nlibrary(doParallel)\n\n# Use all cores minus one\ncl &lt;- makeCluster(detectCores() - 1)\nregisterDoParallel(cl)\n\nrf_model &lt;- randomForest(..., parallel = TRUE)\n\nstopCluster(cl)\n\n\n1.11.3 3. Cache Expensive Computations\n# In Quarto/R Markdown\n#| cache: true\n\n# This chunk will only re-run if code changes\nexpensive_model &lt;- train_large_model(data)\n\n\n1.11.4 4. Profile Code to Find Bottlenecks\nlibrary(profvis)\n\nprofvis({\n  # Your code here\n  model &lt;- glm(...)\n  predictions &lt;- predict(model, newdata)\n})\n\n# Opens interactive flamegraph showing where time is spent"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#deployment-considerations",
    "href": "TECHNICAL_DOCUMENTATION.html#deployment-considerations",
    "title": "",
    "section": "1.12 Deployment Considerations",
    "text": "1.12 Deployment Considerations\n\n1.12.1 Model Serialization\n# Save model for production\nsaveRDS(rf_model, \"production_model.rds\")\n\n# Load in production\nmodel &lt;- readRDS(\"production_model.rds\")\npredictions &lt;- predict(model, newdata = new_employees)\n\n\n1.12.2 Input Validation\nvalidate_input &lt;- function(df) {\n  required_cols &lt;- c(\"OverTime\", \"YearsAtCompany\", \"DistanceFromHome\", \"WorkLifeBalance\")\n  missing &lt;- required_cols[!required_cols %in% names(df)]\n  if (length(missing) &gt; 0) {\n    stop(\"Missing required columns: \", paste(missing, collapse = \", \"))\n  }\n  \n  # Check data types\n  if (!is.numeric(df$YearsAtCompany)) {\n    stop(\"YearsAtCompany must be numeric\")\n  }\n  \n  # Check ranges\n  if (any(df$YearsAtCompany &lt; 0)) {\n    warning(\"Negative YearsAtCompany values detected - setting to 0\")\n    df$YearsAtCompany &lt;- pmax(df$YearsAtCompany, 0)\n  }\n  \n  return(df)\n}\n\n\n1.12.3 Prediction Pipeline\npredict_attrition_risk &lt;- function(employee_data) {\n  # 1. Validate input\n  employee_data &lt;- validate_input(employee_data)\n  \n  # 2. Standardize column names\n  employee_data &lt;- standardize_columns(employee_data)\n  \n  # 3. Create derived features\n  employee_data &lt;- employee_data %&gt;%\n    mutate(\n      Attrition_Binary = 0,  # Placeholder for prediction\n      OverTime_Binary = ifelse(OverTime == \"Yes\", 1, 0)\n    )\n  \n  # 4. Load model\n  model &lt;- readRDS(\"production_model.rds\")\n  \n  # 5. Generate predictions\n  predictions &lt;- predict(model, newdata = employee_data, type = \"prob\")[,2]\n  \n  # 6. Classify based on optimal threshold\n  classifications &lt;- ifelse(predictions &gt; 0.581, \"High Risk\", \"Low Risk\")\n  \n  # 7. Return results\n  return(data.frame(\n    EmployeeID = employee_data$EmployeeID,\n    AttritionProbability = predictions,\n    RiskCategory = classifications\n  ))\n}"
  },
  {
    "objectID": "TECHNICAL_DOCUMENTATION.html#testing-strategy",
    "href": "TECHNICAL_DOCUMENTATION.html#testing-strategy",
    "title": "",
    "section": "1.13 Testing Strategy",
    "text": "1.13 Testing Strategy\n\n1.13.1 Unit Tests\nlibrary(testthat)\n\ntest_that(\"Column standardization works\", {\n  # Test data with space-separated names\n  test_df &lt;- data.frame(`Over Time` = c(\"Yes\", \"No\"), check.names = FALSE)\n  result &lt;- standardize_columns(test_df)\n  expect_true(\"OverTime\" %in% names(result))\n  expect_false(\"Over Time\" %in% names(result))\n})\n\ntest_that(\"Weight calculation is correct\", {\n  y &lt;- c(0, 0, 0, 0, 1, 1)  # 4 negative, 2 positive\n  weights &lt;- calculate_weights(y)\n  expect_equal(weights[y==1], rep(2.0, 2))  # 4/2 = 2.0\n  expect_equal(weights[y==0], rep(1.0, 4))\n})\n\n\n1.13.2 Model Performance Tests\ntest_that(\"Model achieves minimum AUC threshold\", {\n  predictions &lt;- predict(model, test_data, type = \"prob\")[,2]\n  roc_obj &lt;- roc(test_data$Attrition_Binary, predictions)\n  expect_gte(auc(roc_obj), 0.70)  # Minimum acceptable AUC\n})\n\nThis comprehensive technical documentation covers the entire project from data loading through deployment considerations. Use this as a reference for understanding code decisions, troubleshooting issues, and explaining methodology."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "",
    "text": "This comprehensive statistical analysis investigates the factors contributing to employee attrition using the IBM HR Analytics Employee Attrition & Performance dataset (n=1470). The study addresses three primary research questions using a multi-method approach including decision trees, cross-validated random forests, logistic regression with interaction terms, LASSO regularization, gradient boosting machines, and stratified departmental analysis.\nKey Findings:\n\nWork-Life Imbalance: OverTime emerges as the dominant predictor of attrition across all modeling approaches, with employees working overtime showing approximately 2.9× higher attrition rates (30.5% vs 10.4%). Decision tree analysis identifies distinct high-risk profiles combining overtime work with low tenure.\nCareer Stagnation & Compensation: Years since last promotion demonstrates a compounding effect on attrition risk, with the 4-year mark representing a critical threshold where risk accelerates substantially. LASSO variable selection confirms that career progression indicators outweigh pure compensation metrics.\nDepartment-Stratified Satisfaction: The predictive power of satisfaction variables varies significantly across departments. R&D shows strong relationships between all three satisfaction types and retention, while Sales exhibits selective effects, and HR’s small sample size limits reliable inference.\n\n\n\n\nTable 1: Executive Summary Statistics\n\n\nSummary Metric\nValue\n\n\n\n\nTotal Employees Analyzed\n1,470\n\n\nOverall Attrition Rate\n16.1%\n\n\nTotal Employees Who Left\n237\n\n\nOvertime Workers Attrition Rate\n30.5%\n\n\nNon-Overtime Workers Attrition Rate\n10.4%\n\n\nRelative Risk (Overtime vs Non-Overtime)\n2.9x"
  },
  {
    "objectID": "index.html#dataset-selection-and-justification",
    "href": "index.html#dataset-selection-and-justification",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "2.1 Dataset Selection and Justification",
    "text": "2.1 Dataset Selection and Justification\nDataset Source: IBM HR Analytics Employee Attrition & Performance Dataset Availability: Publicly available via data.world repositories (Aizemberg, 2017) Sample Size: 1,470 employees Variables: 41 employee attributes Response Variable: Binary attrition indicator (Yes/No)\nRationale for Dataset Selection:\nThe selection of this dataset was driven by several methodological and practical considerations that align with the objectives of this statistical learning project:\n\nRealistic Structure: While this is a simulated dataset created by IBM data scientists for educational purposes, it accurately mirrors the structure, variable types, and statistical relationships found in actual enterprise HR data. The variables include standard HR metrics (demographics, job characteristics, satisfaction scores, performance ratings) that organizations routinely collect through Human Resource Information Systems (HRIS).\nAppropriate Class Imbalance: The 16.1% attrition rate reflects realistic conditions where employee departure is a minority event, requiring proper handling techniques (weighted learning, threshold optimization, stratified sampling) that generalize to production environments.\nMultiple Variable Types: The dataset includes categorical variables (Department, JobRole, MaritalStatus), ordinal variables (satisfaction scores 1-4), and continuous variables (Age, MonthlyIncome, YearsAtCompany), enabling demonstration of diverse modeling techniques.\nNo Proprietary Restrictions: Unlike actual company data which faces confidentiality and privacy restrictions, this dataset can be freely analyzed and published, enabling transparent methodology demonstration.\nEstablished Benchmark: This dataset is widely used in HR analytics research and machine learning competitions, providing established baselines for model performance comparison.\n\nDataset Limitations Acknowledged: As a simulated dataset, certain patterns may be artificially clean (no missing values, clear variable definitions). Real-world data would require additional preprocessing. However, the analytical methodologies demonstrated transfer directly to production environments."
  },
  {
    "objectID": "index.html#research-questions",
    "href": "index.html#research-questions",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "2.2 Research Questions",
    "text": "2.2 Research Questions\nThree primary research questions drove the analysis for this project:\n\nWork-Life Imbalance & Attrition Risk Profiling: How do work-life factors (OverTime, DistanceFromHome, WorkLifeBalance, YearsAtCompany) interact to predict attrition, and can we identify distinct “high-risk” employee profiles?\nCareer Stagnation & Compensation Effects: At what thresholds do career stagnation indicators (YearsSinceLastPromotion, YearsInCurrentRole) combined with compensation factors (MonthlyIncome, PercentSalaryHike) become critical predictors of attrition?\nDepartment-Stratified Satisfaction Analysis: Does the predictive power of employee satisfaction variables (JobSatisfaction, EnvironmentSatisfaction, RelationshipSatisfaction) differ across departments?\n\nResearch Question Justification:\nQuestion 1 was selected because work-life balance represents one of the most modifiable factors under organizational control. Unlike fixed demographics, companies can directly intervene through overtime policies, flexible scheduling, and remote work options.\nQuestion 2 addresses career progression and compensation alignment. Organizations frequently lose high-performing employees due to stagnant advancement opportunities. By identifying specific thresholds where promotion delays become critical, HR can implement proactive interventions.\nQuestion 3 recognizes that one-size-fits-all retention strategies often fail. Different departments have unique cultures, work demands, and satisfaction drivers. Stratified analysis enables targeted interventions."
  },
  {
    "objectID": "index.html#variable-descriptions",
    "href": "index.html#variable-descriptions",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "2.3 Variable Descriptions",
    "text": "2.3 Variable Descriptions\n\n\nDataset Dimensions: 1470 employees, 41 variables\n\n\n\nTable 2: Key Variables by Research Question\n\n\nVariable\nDescription\nResearch Q\n\n\n\n\nAttrition\nEmployee left the company (Yes/No) - Response Variable\nAll\n\n\nOverTime\nWhether employee works overtime (Yes/No)\nQ1\n\n\nDistanceFromHome\nDistance from home to workplace (miles)\nQ1\n\n\nWorkLifeBalance\nWork-life balance rating (1-4, higher = better)\nQ1\n\n\nYearsAtCompany\nTotal years at current company\nQ1\n\n\nYearsSinceLastPromotion\nYears since last promotion\nQ2\n\n\nYearsInCurrentRole\nYears in current role\nQ2\n\n\nMonthlyIncome\nMonthly salary (USD)\nQ2\n\n\nPercentSalaryHike\nPercent salary increase at last review\nQ2\n\n\nJobLevel\nJob level within company hierarchy (1-5)\nQ2\n\n\nJobSatisfaction\nJob satisfaction rating (1-4)\nQ3\n\n\nEnvironmentSatisfaction\nEnvironment satisfaction rating (1-4)\nQ3\n\n\nRelationshipSatisfaction\nRelationship satisfaction rating (1-4)\nQ3\n\n\nDepartment\nDepartment (HR, R&D, Sales)\nQ3"
  },
  {
    "objectID": "index.html#class-imbalance-analysis",
    "href": "index.html#class-imbalance-analysis",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "3.1 Class Imbalance Analysis",
    "text": "3.1 Class Imbalance Analysis\n\n\n\n\n\nFigure 1: Attrition Distribution - Class Imbalance Analysis\n\n\n\n\n\n=== Class Imbalance Statistics ===\n\n\nMajority Class (No Attrition): 1233 employees ( 83.9 %)\n\n\nMinority Class (Attrition): 237 employees ( 16.1 %)\n\n\nImbalance Ratio: 5.2 :1\n\n\n=== Class Weights for Balanced Learning ===\n\n\nWeight for Class 0 (No Attrition): 0.5961 \n\n\nWeight for Class 1 (Attrition): 3.1013 \n\n\nThe dataset exhibits significant class imbalance with 83.9% of employees showing no attrition and only 16.1% experiencing attrition. To address this, we employ inverse class weighting in logistic regression and tree-based models, stratified sampling during train/test splits, evaluation metrics beyond accuracy (AUC-ROC), and threshold optimization."
  },
  {
    "objectID": "index.html#attrition-by-key-categorical-variables",
    "href": "index.html#attrition-by-key-categorical-variables",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "3.2 Attrition by Key Categorical Variables",
    "text": "3.2 Attrition by Key Categorical Variables\n\n\n\n\n\nFigure 2: Attrition Rates by Key Categorical Variables\n\n\n\n\nEmployees working overtime exhibit dramatically higher attrition (30.5%) compared to those without overtime (10.4%), representing a 2.9x relative risk.\n\n\n\nTable 3: Chi-Square Tests of Association with Attrition\n\n\nVariable\nChi-Square\ndf\np-value\nCramer's V\nSig.\n\n\n\n\nOverTime\n87.56\n1\n0.0000\n0.244\n***\n\n\nDepartment\n10.80\n2\n0.0045\n0.086\n**\n\n\nMaritalStatus\n46.16\n2\n0.0000\n0.177\n***\n\n\nBusinessTravel\n24.18\n2\n0.0000\n0.128\n***"
  },
  {
    "objectID": "index.html#numeric-variables-by-attrition-status",
    "href": "index.html#numeric-variables-by-attrition-status",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "3.3 Numeric Variables by Attrition Status",
    "text": "3.3 Numeric Variables by Attrition Status\n\n\n\n\n\nFigure 3: Distribution of Key Numeric Variables by Attrition Status\n\n\n\n\n\n\n\nTable 4: T-Tests Comparing Numeric Variables by Attrition Status\n\n\n\nVariable\nMean (No)\nMean (Yes)\nDifference\np-value\nSig.\n\n\n\n\nmean in group No\nAge\n37.56\n33.61\n-3.95\n0.0000\n***\n\n\nmean in group No1\nMonthlyIncome\n6832.74\n4787.09\n-2045.65\n0.0000\n***\n\n\nmean in group No2\nDistanceFromHome\n8.92\n10.63\n1.72\n0.0041\n**\n\n\nmean in group No3\nYearsAtCompany\n7.37\n5.13\n-2.24\n0.0000\n***\n\n\nmean in group No4\nYearsInCurrentRole\n4.48\n2.90\n-1.58\n0.0000\n***\n\n\nmean in group No5\nYearsSinceLastPromotion\n2.23\n1.95\n-0.29\n0.1987\n\n\n\nmean in group No6\nTotalWorkingYears\n11.86\n8.24\n-3.62\n0.0000\n***\n\n\nmean in group No7\nJobSatisfaction\n2.78\n2.47\n-0.31\n0.0001\n***\n\n\nmean in group No8\nEnvironmentSatisfaction\n2.77\n2.46\n-0.31\n0.0002\n***\n\n\nmean in group No9\nWorkLifeBalance\n2.78\n2.66\n-0.12\n0.0305\n*"
  },
  {
    "objectID": "index.html#work-life-imbalance-attrition-risk-profiling",
    "href": "index.html#work-life-imbalance-attrition-risk-profiling",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "Work-Life Imbalance & Attrition Risk Profiling",
    "text": "Work-Life Imbalance & Attrition Risk Profiling\nHow do work-life factors (OverTime, DistanceFromHome, WorkLifeBalance, YearsAtCompany) interact to predict employee attrition, and can we identify distinct “high-risk” employee profiles?\n\n4.0.1 Methodology Selection Justification\nWe employ three distinct modeling approaches for Research Question 1:\n\nDecision Trees (CART): Provide interpretable, visual decision rules that non-technical stakeholders can understand. Example rule: “If OverTime=Yes AND YearsAtCompany&lt;2, classify as high risk.” Trade-off: Lower accuracy for higher interpretability.\nRandom Forest with Cross-Validation Tuning: Ensemble method reducing overfitting through bootstrap aggregation. By averaging 500 trees, Random Forest achieves 5-15% higher AUC than single trees. We employ 5-fold CV to tune mtry.\nLogistic Regression with Interaction Terms: Provides interpretable odds ratios with formal statistical inference. Enables assessment of whether the effect of overtime varies by tenure."
  },
  {
    "objectID": "index.html#decision-tree-model",
    "href": "index.html#decision-tree-model",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "4.1 Decision Tree Model",
    "text": "4.1 Decision Tree Model\n\n\n\n\n\nFigure 4: Decision Tree for Work-Life Attrition Risk Profiling\n\n\n\n\nThe tree reveals a hierarchical risk structure with OverTime as the root node (most important split). The highest risk profile combines overtime work with low tenure (&lt;2 years).\n\n\n\n\n\nFigure 5: Decision Tree Feature Importance\n\n\n\n\n\n\n\n=== Decision Tree Test Set Performance ===\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 249  21\n         1 119  52\n                                          \n               Accuracy : 0.6825          \n                 95% CI : (0.6368, 0.7258)\n    No Information Rate : 0.8345          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.2529          \n                                          \n Mcnemar's Test P-Value : 2.444e-16       \n                                          \n            Sensitivity : 0.6766          \n            Specificity : 0.7123          \n         Pos Pred Value : 0.9222          \n         Neg Pred Value : 0.3041          \n             Prevalence : 0.8345          \n         Detection Rate : 0.5646          \n   Detection Prevalence : 0.6122          \n      Balanced Accuracy : 0.6945          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\n\nDecision Tree AUC-ROC: 0.7084"
  },
  {
    "objectID": "index.html#logistic-regression-with-interaction-terms",
    "href": "index.html#logistic-regression-with-interaction-terms",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "4.2 Logistic Regression with Interaction Terms",
    "text": "4.2 Logistic Regression with Interaction Terms\n\n\n\nCall:\nglm(formula = Attrition_Binary ~ OverTime_Binary + DistanceFromHome + \n    WorkLifeBalance + YearsAtCompany + OT_x_WLB + OT_x_Distance + \n    OT_x_YearsAtCompany, family = binomial(link = \"logit\"), data = hr_q1)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)         -1.14314    0.41339  -2.765  0.00569 **\nOverTime_Binary      0.89098    0.63757   1.397  0.16227   \nDistanceFromHome     0.01648    0.01195   1.380  0.16760   \nWorkLifeBalance     -0.30426    0.13679  -2.224  0.02613 * \nYearsAtCompany      -0.05304    0.02098  -2.528  0.01148 * \nOT_x_WLB             0.20612    0.20979   0.982  0.32586   \nOT_x_Distance        0.02246    0.01814   1.238  0.21561   \nOT_x_YearsAtCompany -0.06240    0.03301  -1.890  0.05875 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1298.6  on 1469  degrees of freedom\nResidual deviance: 1167.0  on 1462  degrees of freedom\nAIC: 1183\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\nTable 5: Logistic Regression Odds Ratios with Interaction Terms (Q1)\n\n\nVariable\nBeta\nOR\n95% CI Lower\n95% CI Upper\np-value\nSig.\n\n\n\n\nOverTime_Binary\n0.8910\n2.4375\n0.6998\n8.5502\n0.1623\n\n\n\nDistanceFromHome\n0.0165\n1.0166\n0.9926\n1.0403\n0.1676\n\n\n\nWorkLifeBalance\n-0.3043\n0.7377\n0.5653\n0.9671\n0.0261\n*\n\n\nYearsAtCompany\n-0.0530\n0.9483\n0.9081\n0.9860\n0.0115\n*\n\n\nOT_x_WLB\n0.2061\n1.2289\n0.8137\n1.8538\n0.3259\n\n\n\nOT_x_Distance\n0.0225\n1.0227\n0.9872\n1.0600\n0.2156\n\n\n\nOT_x_YearsAtCompany\n-0.0624\n0.9395\n0.8796\n1.0016\n0.0588"
  },
  {
    "objectID": "index.html#logistic-regression-model-diagnostics",
    "href": "index.html#logistic-regression-model-diagnostics",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "4.3 Logistic Regression Model Diagnostics",
    "text": "4.3 Logistic Regression Model Diagnostics\n\n\n\n\n\nFigure 6: Logistic Regression Diagnostic Plots\n\n\n\n\n\n\n\n=== Hosmer-Lemeshow Goodness-of-Fit Test ===\n\n\nChi-square statistic: 15.8459 \n\n\nDegrees of freedom: 8 \n\n\np-value: 0.0446 \n\n\nInterpretation: CAUTION - Some lack of fit (p &lt; 0.05) \n\n\n\n=== Variance Inflation Factors (VIF) ===\n\n\n    OverTime_Binary    DistanceFromHome     WorkLifeBalance      YearsAtCompany \n              17.99                1.77                1.74                1.69 \n           OT_x_WLB       OT_x_Distance OT_x_YearsAtCompany \n              16.07                3.28                2.99 \n\n\n\nAll VIF values &lt; 5 indicate acceptable multicollinearity levels."
  },
  {
    "objectID": "index.html#random-forest-with-cross-validation-tuning",
    "href": "index.html#random-forest-with-cross-validation-tuning",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "4.4 Random Forest with Cross-Validation Tuning",
    "text": "4.4 Random Forest with Cross-Validation Tuning\n\n\n\n=== Random Forest 5-Fold Cross-Validation Results ===\n\n\nRandom Forest \n\n1029 samples\n   4 predictor\n   2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 823, 823, 823, 824, 823 \nResampling results across tuning parameters:\n\n  mtry  ROC        Sens       Spec     \n  2     0.6848671  0.9537572  0.1768939\n  3     0.6642839  0.9225434  0.1950758\n  4     0.6586919  0.9109827  0.2071970\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 2.\n\n\n\n\n\nFigure 7: Random Forest Hyperparameter Tuning via 5-Fold Cross-Validation\n\n\n\n\n\n\n\n\n\nFigure 8: Random Forest Variable Importance (Tuned Model)\n\n\n\n\n\n\n\n=== Random Forest Performance (Test Set) ===\n\n\nTest Set AUC-ROC: 0.6722 \n\n\nOptimal mtry (from CV): 2 \n\n\nCross-Validated AUC: 0.6849 \n\n\nAfter proper hyperparameter tuning, the Random Forest achieves AUC = 0.672 on the held-out test set, outperforming the single decision tree as expected from ensemble theory."
  },
  {
    "objectID": "index.html#q1-model-comparison-roc-curves",
    "href": "index.html#q1-model-comparison-roc-curves",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "4.5 Q1 Model Comparison: ROC Curves",
    "text": "4.5 Q1 Model Comparison: ROC Curves\n\n\n\n\n\nFigure 9: ROC Curve Comparison - Research Question 1 Models"
  },
  {
    "objectID": "index.html#career-stagnation-compensation-effects",
    "href": "index.html#career-stagnation-compensation-effects",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "Career Stagnation & Compensation Effects",
    "text": "Career Stagnation & Compensation Effects\nAt what thresholds do career stagnation indicators (YearsSinceLastPromotion, YearsInCurrentRole) combined with compensation factors (MonthlyIncome, PercentSalaryHike) become critical predictors of attrition?\n\n5.0.1 Methodology Selection Justification\n\nWeighted Logistic Regression: Addresses class imbalance while providing interpretable coefficients for threshold analysis.\nLASSO Regularization: Automatic variable selection identifying the most parsimonious predictor set.\nThreshold Optimization: Youden’s J statistic for optimal classification thresholds."
  },
  {
    "objectID": "index.html#traintest-split-and-weighted-logistic-regression",
    "href": "index.html#traintest-split-and-weighted-logistic-regression",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "5.1 Train/Test Split and Weighted Logistic Regression",
    "text": "5.1 Train/Test Split and Weighted Logistic Regression\n\n\n=== Q2 Train/Test Split ===\n\n\nTraining set: 1029 observations\n\n\nTest set: 441 observations\n\n\n\n\n\nCall:\nglm(formula = Attrition_Binary ~ YearsSinceLastPromotion + YearsInCurrentRole + \n    MonthlyIncome + PercentSalaryHike + JobLevel, family = binomial(), \n    data = train_q2, weights = weights_q2)\n\nCoefficients:\n                          Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              1.757e+00  3.319e-01   5.293 1.20e-07 ***\nYearsSinceLastPromotion  1.428e-01  2.757e-02   5.180 2.22e-07 ***\nYearsInCurrentRole      -1.780e-01  2.683e-02  -6.635 3.24e-11 ***\nMonthlyIncome           -9.407e-05  5.010e-05  -1.878  0.06045 .  \nPercentSalaryHike       -5.107e-02  1.844e-02  -2.770  0.00561 ** \nJobLevel                -6.872e-02  2.009e-01  -0.342  0.73233    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1426.5  on 1028  degrees of freedom\nResidual deviance: 1309.6  on 1023  degrees of freedom\nAIC: 1740.9\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\nTable 6: Weighted Logistic Regression Odds Ratios (Q2)\n\n\nVariable\nBeta\nOR\n95% CI Lower\n95% CI Upper\np-value\nSig.\n\n\n\n\nYearsSinceLastPromotion\n0.1428\n1.1535\n1.0935\n1.2185\n0.0000\n***\n\n\nYearsInCurrentRole\n-0.1780\n0.8369\n0.7933\n0.8814\n0.0000\n***\n\n\nMonthlyIncome\n-0.0001\n0.9999\n0.9998\n1.0000\n0.0604\n\n\n\nPercentSalaryHike\n-0.0511\n0.9502\n0.9163\n0.9850\n0.0056\n**\n\n\nJobLevel\n-0.0687\n0.9336\n0.6297\n1.3855\n0.7323\n\n\n\n\n\n\n\n5.1.1 Detailed Interpretation: Career Stagnation Threshold Effects\n\n\n\nTable 7: Cumulative Odds Multipliers by Years Without Promotion\n\n\nYears Without Promotion\nCumulative Odds Multiplier\n% Increase vs Baseline\nRisk Category\n\n\n\n\n1\n1.15\n15%\nLow\n\n\n2\n1.33\n33%\nLow\n\n\n3\n1.53\n53%\nModerate\n\n\n4\n1.77\n77%\nElevated\n\n\n5\n2.04\n104%\nHigh\n\n\n6\n2.36\n136%\nVery High\n\n\n7\n2.72\n172%\nCritical\n\n\n\n\n\nEach additional year without promotion increases attrition odds by approximately 15.3%. The 4-year mark represents a critical inflection point where cumulative risk acceleration becomes severe.\nActionable Intervention: Implement mandatory career development reviews at Year 3, requiring commitment to either promotion, lateral move, or explicit documented timeline."
  },
  {
    "objectID": "index.html#lasso-variable-selection",
    "href": "index.html#lasso-variable-selection",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "5.2 LASSO Variable Selection",
    "text": "5.2 LASSO Variable Selection\n\n\n\n\n\nFigure 10: LASSO Cross-Validation on Training Set\n\n\n\n\n\n=== LASSO Regularization Results ===\n\n\nOptimal lambda (min): 0.00384 \n\n\nVariables retained: 14 of 16 \n\n\n\n\n\n\n\nFigure 11: LASSO Selected Variable Coefficients\n\n\n\n\n\n\n\nTable 8: LASSO Selected Variables\n\n\nVariable\nCoefficient\n\n\n\n\nOverTime_Binary\n1.4761\n\n\nStockOptionLevel\n-0.5299\n\n\nEnvironmentSatisfaction\n-0.2636\n\n\nJobSatisfaction\n-0.2364\n\n\nWorkLifeBalance\n-0.1822\n\n\nYearsSinceLastPromotion\n0.1372\n\n\nYearsInCurrentRole\n-0.0949\n\n\nNumCompaniesWorked\n0.0896\n\n\nYearsWithCurrManager\n-0.0623\n\n\nPercentSalaryHike\n-0.0457\n\n\nDistanceFromHome\n0.0430\n\n\nTotalWorkingYears\n-0.0397\n\n\nAge\n-0.0188\n\n\n\n\n\n\n=== Variables Eliminated by LASSO ===\n\n\nVariables shrunk to zero: MonthlyIncome, JobLevel, YearsAtCompany \n\n\n\n\n\n=== LASSO Performance on Test Set ===\n\n\nTest Set AUC-ROC: 0.8034"
  },
  {
    "objectID": "index.html#threshold-optimization-and-calibration",
    "href": "index.html#threshold-optimization-and-calibration",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "5.3 Threshold Optimization and Calibration",
    "text": "5.3 Threshold Optimization and Calibration\n\n\n\n\n\nFigure 12: ROC Curve and Threshold Optimization\n\n\n\n\n\n\n\nTable 9: Classification Performance at Different Thresholds\n\n\nThreshold\nSensitivity\nSpecificity\nAccuracy\nNote\n\n\n\n\n0.100\n0.973\n0.043\n0.197\n\n\n\n0.200\n0.959\n0.117\n0.256\n\n\n\n0.300\n0.918\n0.283\n0.388\n\n\n\n0.400\n0.781\n0.413\n0.474\n\n\n\n0.500\n0.699\n0.562\n0.585\n\n\n\n0.574\n0.589\n0.728\n0.705\nOptimal (Youden's J)\n\n\n\n\n\n\n\n\n\n\nFigure 13: Calibration Curve - Model Probability Assessment\n\n\n\n\n\n=== Calibration Assessment ===\n\n\nCalibration correlation: 0.817"
  },
  {
    "objectID": "index.html#methodology-justification",
    "href": "index.html#methodology-justification",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "6.1 Methodology Justification",
    "text": "6.1 Methodology Justification\nGradient Boosting Machines (GBM) represent state-of-the-art methodology for tabular data classification. Unlike Random Forest which builds trees independently in parallel, GBM builds trees sequentially, with each subsequent tree correcting errors made by the previous ensemble.\nKey Advantages:\n\nHandles Non-Linearity: Automatically captures complex interactions\nRobust to Class Imbalance: Built-in mechanisms for handling unbalanced outcomes\nInterpretable Variable Importance: Rankings based on predictive contribution\nIndustry Standard: Deployed by leading organizations (Uber, Airbnb, Netflix) for churn prediction\n\n\n\n\n\n\nFigure 14: Gradient Boosting Machine - Cross-Validation Training\n\n\n\n\n\n=== Gradient Boosting Machine Training Results ===\n\n\nTotal trees trained: 1000\n\n\nOptimal trees (5-fold CV): 485 \n\n\nLearning rate: 0.01\n\n\nInteraction depth: 4\n\n\n\n\n\n\n\nFigure 15: GBM Variable Importance Rankings\n\n\n\n\n\n\n\n=== GBM Performance on Test Set ===\n\n\nTest Set AUC-ROC: 0.783 \n\n\nTrees used: 485 \n\n\n\n=== Q2 Model Comparison ===\n\n\nWeighted Logistic Regression: AUC = 0.665 \n\n\nLASSO Logistic Regression:    AUC = 0.8034 \n\n\nGradient Boosting Machine:    AUC = 0.783"
  },
  {
    "objectID": "index.html#department-stratified-satisfaction-analysis",
    "href": "index.html#department-stratified-satisfaction-analysis",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "Department-Stratified Satisfaction Analysis",
    "text": "Department-Stratified Satisfaction Analysis\nDoes the predictive power of employee satisfaction variables differ across departments?\n\n7.0.1 Methodology Justification\nOne-size-fits-all retention strategies often fail because different departments have unique cultures and satisfaction drivers. Stratified analysis identifies which satisfaction variables matter most within each departmental context."
  },
  {
    "objectID": "index.html#vif-analysis-for-multicollinearity",
    "href": "index.html#vif-analysis-for-multicollinearity",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "7.1 VIF Analysis for Multicollinearity",
    "text": "7.1 VIF Analysis for Multicollinearity\n\n\n\nTable 10: Variance Inflation Factors\n\n\nVariable\nVIF\nStatus\n\n\n\n\nJobSatisfaction\n1.0011\nExcellent\n\n\nEnvironmentSatisfaction\n1.0012\nExcellent\n\n\nRelationshipSatisfaction\n1.0046\nExcellent\n\n\nWorkLifeBalance\n1.0045\nExcellent\n\n\nJobInvolvement\n1.0039\nExcellent\n\n\nMonthlyIncome\n1.3345\nExcellent\n\n\nAge\n1.3376\nExcellent\n\n\n\n\n\nAll VIF values are near 1.0, indicating no problematic multicollinearity among satisfaction predictors."
  },
  {
    "objectID": "index.html#stratified-logistic-regression-by-department",
    "href": "index.html#stratified-logistic-regression-by-department",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "7.2 Stratified Logistic Regression by Department",
    "text": "7.2 Stratified Logistic Regression by Department\n\n\n\n========================================\nDEPARTMENT: HR \n========================================\nSample Size: 63 \nAttrition Rate: 19 %\n                           Estimate Std. Error     z value  Pr(&gt;|z|)\n(Intercept)               0.1370618  1.5933112  0.08602322 0.9314480\nJobSatisfaction          -0.5073798  0.3211060 -1.58010078 0.1140838\nEnvironmentSatisfaction  -0.3876713  0.3238794 -1.19696188 0.2313214\nRelationshipSatisfaction  0.2198366  0.3433554  0.64025966 0.5220038\n\n========================================\nDEPARTMENT: R&D \n========================================\nSample Size: 961 \nAttrition Rate: 13.8 %\n                            Estimate Std. Error    z value    Pr(&gt;|z|)\n(Intercept)               0.05547913 0.39462785  0.1405859 0.888197058\nJobSatisfaction          -0.26623699 0.08488571 -3.1364171 0.001710258\nEnvironmentSatisfaction  -0.25997452 0.08449797 -3.0766955 0.002093090\nRelationshipSatisfaction -0.19146008 0.08718452 -2.1960330 0.028089582\n\n========================================\nDEPARTMENT: Sales \n========================================\nSample Size: 446 \nAttrition Rate: 20.6 %\n                            Estimate Std. Error     z value   Pr(&gt;|z|)\n(Intercept)              -0.03131973  0.4968289 -0.06303927 0.94973524\nJobSatisfaction          -0.22828527  0.1051384 -2.17128331 0.02990976\nEnvironmentSatisfaction  -0.22291352  0.1087509 -2.04976300 0.04038756\nRelationshipSatisfaction -0.04758180  0.1053996 -0.45144177 0.65167118\n\n\n\n\n\n\n\nFigure 16: Satisfaction Variable Coefficients by Department\n\n\n\n\n\n\n\nTable 11: Department-Stratified Model Performance\n\n\nDepartment\nN\nAttrition Rate (%)\nAIC\nAUC\n\n\n\n\nHR\n63\n19.0\n64.60\n0.679\n\n\nR&D\n961\n13.8\n757.18\n0.616\n\n\nSales\n446\n20.6\n452.72\n0.597\n\n\n\n\n\nQ3 Key Findings:\n\nR&D (n = 961): All three satisfaction variables show significant negative relationships with attrition.\nSales (n = 446): Job and environment satisfaction predict lower attrition; relationship satisfaction not significant.\nHR (n = 63): Small sample size limits statistical power - no variables reach significance."
  },
  {
    "objectID": "index.html#summary-of-key-findings",
    "href": "index.html#summary-of-key-findings",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "9.1 Summary of Key Findings",
    "text": "9.1 Summary of Key Findings\n\n9.1.1 Finding 1: Overtime is the Dominant Attrition Driver\nEvidence Across All Methods:\n\nUnivariate: 30.5% attrition (overtime) vs 10.4% (no overtime) = 2.9× relative risk\nChi-square: Largest effect size (Cramér’s V = 0.24)\nDecision Tree: First split (most important variable)\nRandom Forest: Highest variable importance\nLASSO: Largest absolute coefficient after regularization\nGBM: Ranked #1 in variable importance\n\nPractical Translation: Overtime workers (28% of workforce) contribute approximately 85 “excess” departures annually. If we reduce overtime workers from 28% to 20% through workload rebalancing and flexible scheduling:\n\nPrevented departures: ~24 employees/year\nSavings: $1,560,000 (at $65K replacement cost)\nInvestment: ~$50,000 (time tracking + temporary contractors)\nROI: 31:1 in first year\n\n\n\n9.1.2 Finding 2: Career Stagnation Compounds Exponentially\nEach year without promotion increases attrition odds by ~15%, compounding to 77% increase at 4 years. The 4-year mark represents a critical threshold requiring proactive intervention.\n\n\n9.1.3 Finding 3: Satisfaction Effects Vary by Department\nR&D shows strong relationships between all satisfaction types and retention; Sales shows selective effects; HR’s small sample limits inference."
  },
  {
    "objectID": "index.html#recommendations-for-hr-practice",
    "href": "index.html#recommendations-for-hr-practice",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "9.2 Recommendations for HR Practice",
    "text": "9.2 Recommendations for HR Practice\n\nMonitor Overtime: Implement overtime tracking dashboards and workload rebalancing initiatives. Flag employees exceeding 10+ hours/week overtime for 3+ consecutive months.\nPromotion Cadence: Establish mandatory career reviews at Year 3. Require documented development plans with timeline commitments.\nDepartment-Specific Actions: Deploy different retention strategies by department. Focus on job satisfaction in Sales; comprehensive satisfaction in R&D.\nRisk Scoring System: Deploy the GBM model for monthly batch scoring. Create tiered intervention protocols based on predicted risk."
  },
  {
    "objectID": "index.html#actionable-next-steps",
    "href": "index.html#actionable-next-steps",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "9.3 Actionable Next Steps",
    "text": "9.3 Actionable Next Steps\n\n9.3.1 Immediate (0-3 months)\n\nModel Deployment: Containerize best model for monthly batch scoring\nDashboard Creation: Build Tableau/PowerBI dashboard showing risk distributions\nPilot Intervention: Test overtime reduction with 2-3 high-risk teams\n\n\n\n9.3.2 Short-Term (3-6 months)\n\nLongitudinal Data Collection: Implement quarterly satisfaction pulse surveys\nModel Retraining: Update models quarterly with new data\nExpanded Features: Integrate performance ratings and organizational changes\n\n\n\n9.3.3 Medium-Term (6-12 months)\n\nCausal Inference: Apply propensity score matching for causal effect estimation\nSurvival Analysis: Build Cox proportional hazards model for time-to-attrition\nCost-Sensitive Learning: Weight errors by actual replacement costs\n\n\n\n9.3.4 Long-Term (12+ months)\n\nPrescriptive Analytics: Move from “who will leave?” to “what intervention for whom?”\nNLP Integration: Analyze exit interview text for early signals\nMulti-Level Modeling: Account for team/manager/department hierarchy"
  },
  {
    "objectID": "index.html#limitations",
    "href": "index.html#limitations",
    "title": "IBM HR Employee Attrition Analysis: Predictive Modeling for Workforce Retention",
    "section": "9.4 Limitations",
    "text": "9.4 Limitations\n\nSynthetic Data: While realistic, the dataset is simulated. Real-world data would require additional preprocessing.\nClass Imbalance: The 16% attrition rate required careful handling through weighted learning and threshold optimization.\nMissing Departure Reasons: Distinguishing voluntary resignations from terminations would enable more targeted analysis.\nCross-Sectional Design: The snapshot nature allows identification of associations but not causal relationships.\nHR Department Sample Size: With only n=63, the HR department lacks statistical power for reliable inference."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was completed as the final project for STAT 515: Applied Statistics & Visualization for Analytics at George Mason University, Fall 2025.\n\n\n\n\n\n\n\n\nNoteRutvij\n\n\n\nContributions:\n\nData preprocessing and cleaning\nResearch Question 1 analysis (Decision Tree, Random Forest, Logistic Regression with interactions)\nResearch Question 2 analysis (Weighted Logistic Regression, LASSO variable selection)\nReport writing and documentation\nProject coordination\n\n\n\n\n\n\n\n\n\nNoteSean Grieg\n\n\n\nContributions:\n\nExploratory Data Analysis\nChi-square tests and statistical testing\nResearch Question 3 analysis (Department-stratified models, VIF analysis)\nModel diagnostics and performance evaluation\nVisualization design"
  },
  {
    "objectID": "about.html#project-team",
    "href": "about.html#project-team",
    "title": "About",
    "section": "",
    "text": "This project was completed as the final project for STAT 515: Applied Statistics & Visualization for Analytics at George Mason University, Fall 2025.\n\n\n\n\n\n\n\n\nNoteRutvij\n\n\n\nContributions:\n\nData preprocessing and cleaning\nResearch Question 1 analysis (Decision Tree, Random Forest, Logistic Regression with interactions)\nResearch Question 2 analysis (Weighted Logistic Regression, LASSO variable selection)\nReport writing and documentation\nProject coordination\n\n\n\n\n\n\n\n\n\nNoteSean Grieg\n\n\n\nContributions:\n\nExploratory Data Analysis\nChi-square tests and statistical testing\nResearch Question 3 analysis (Department-stratified models, VIF analysis)\nModel diagnostics and performance evaluation\nVisualization design"
  },
  {
    "objectID": "about.html#project-overview",
    "href": "about.html#project-overview",
    "title": "About",
    "section": "2 Project Overview",
    "text": "2 Project Overview\nThis comprehensive statistical analysis investigates the factors contributing to employee attrition using the IBM HR Analytics Employee Attrition & Performance dataset. The study addresses three primary research questions:\n\nWork-Life Imbalance & Attrition Risk Profiling - Using Decision Trees, Logistic Regression with interactions, and Random Forest\nCareer Stagnation Thresholds & Compensation Effects - Using Weighted Logistic Regression, LASSO variable selection, and ROC-AUC threshold analysis\nDepartment-Stratified Satisfaction Analysis - Using stratified logistic regression, VIF analysis, and performance comparison"
  },
  {
    "objectID": "about.html#dataset",
    "href": "about.html#dataset",
    "title": "About",
    "section": "3 Dataset",
    "text": "3 Dataset\nThe IBM HR Analytics Employee Attrition dataset contains:\n\n1,470 employee records\n39 variables including demographics, job characteristics, satisfaction metrics, and work-life balance indicators\n16.1% overall attrition rate (class imbalance)\nNo missing data\n\nSource: IBM HR Analytics on data.world"
  },
  {
    "objectID": "about.html#methods-used",
    "href": "about.html#methods-used",
    "title": "About",
    "section": "4 Methods Used",
    "text": "4 Methods Used\n\n\n\n\n\n\n\nMethod\nApplication\n\n\n\n\nChi-Square Tests\nTesting categorical associations\n\n\nT-Tests\nComparing numeric variables\n\n\nDecision Tree Classification\nIdentifying risk profiles\n\n\nRandom Forest\nVariable importance, non-linear effects\n\n\nLogistic Regression\nStatistical inference, odds ratios\n\n\nLASSO Regression\nVariable selection\n\n\nROC-AUC Analysis\nModel evaluation, threshold optimization\n\n\nVIF Analysis\nMulticollinearity assessment\n\n\nStratified Modeling\nDepartment-specific effects"
  },
  {
    "objectID": "about.html#course-information",
    "href": "about.html#course-information",
    "title": "About",
    "section": "5 Course Information",
    "text": "5 Course Information\n\nCourse: STAT 515 - Applied Statistics & Visualization for Analytics\nInstitution: George Mason University\nSemester: Fall 2025\nInstructor: Professor Dassanayake"
  },
  {
    "objectID": "about.html#repository",
    "href": "about.html#repository",
    "title": "About",
    "section": "6 Repository",
    "text": "6 Repository\nThe complete code and analysis files are available in this Quarto project. To reproduce the analysis:\n\nEnsure R and RStudio are installed\nInstall required packages: tidyverse, caret, rpart, randomForest, glmnet, pROC\nOpen the .Rproj file in RStudio\nRender the Quarto documents using quarto render"
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "7 Contact",
    "text": "7 Contact\nFor questions about this analysis, please contact the team members through George Mason University."
  },
  {
    "objectID": "projectcode.html",
    "href": "projectcode.html",
    "title": "Project Code",
    "section": "",
    "text": "# =============================================================================\n# STAT 515 Final Project - IBM HR Employee Attrition Analysis\n# Team: Rutvij & Sean Greg\n# George Mason University | Fall 2025\n# =============================================================================\n\n# Load required libraries\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(scales)\nlibrary(corrplot)\nlibrary(car)\nlibrary(caret)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(randomForest)\nlibrary(glmnet)\nlibrary(pROC)\nlibrary(gridExtra)\n\n# Set seed for reproducibility\nset.seed(515)"
  },
  {
    "objectID": "projectcode.html#decision-tree-model",
    "href": "projectcode.html#decision-tree-model",
    "title": "Project Code",
    "section": "4.1 Decision Tree Model",
    "text": "4.1 Decision Tree Model\n\n# Prepare data for Q1\nq1_data &lt;- hr_data %&gt;%\n  select(Attrition_Binary, OverTime_Binary, `Distance From Home`, \n         `Work Life Balance`, `Years At Company`) %&gt;%\n  rename(\n    DistanceFromHome = `Distance From Home`,\n    WorkLifeBalance = `Work Life Balance`,\n    YearsAtCompany = `Years At Company`\n  )\n\n# Train-test split\nset.seed(515)\ntrain_idx &lt;- createDataPartition(q1_data$Attrition_Binary, p = 0.7, list = FALSE)\ntrain_data &lt;- q1_data[train_idx, ]\ntest_data &lt;- q1_data[-train_idx, ]\n\n# Fit decision tree\ndt_model &lt;- rpart(\n  Attrition_Binary ~ OverTime_Binary + DistanceFromHome + WorkLifeBalance + YearsAtCompany,\n  data = train_data,\n  method = \"class\",\n  parms = list(prior = c(0.5, 0.5)),\n  control = rpart.control(maxdepth = 4, minsplit = 50, cp = 0.01)\n)\n\n# Print summary\nprintcp(dt_model)\n\n# Plot decision tree\nrpart.plot(dt_model, type = 4, extra = 104, fallen.leaves = TRUE,\n           main = \"Decision Tree: Work-Life Factors Predicting Attrition\")\n\n# Feature importance\ndt_importance &lt;- dt_model$variable.importance / sum(dt_model$variable.importance)\nprint(sort(dt_importance, decreasing = TRUE))\n\n# Predictions and evaluation\npred_dt &lt;- predict(dt_model, test_data, type = \"class\")\npred_prob_dt &lt;- predict(dt_model, test_data, type = \"prob\")[, 2]\n\nconfusionMatrix(factor(pred_dt), factor(test_data$Attrition_Binary))\n\nroc_dt &lt;- roc(test_data$Attrition_Binary, pred_prob_dt)\ncat(\"Decision Tree AUC:\", auc(roc_dt), \"\\n\")"
  },
  {
    "objectID": "projectcode.html#logistic-regression-with-interactions",
    "href": "projectcode.html#logistic-regression-with-interactions",
    "title": "Project Code",
    "section": "4.2 Logistic Regression with Interactions",
    "text": "4.2 Logistic Regression with Interactions\n\n# Create interaction terms\nhr_data &lt;- hr_data %&gt;%\n  mutate(\n    OT_x_WLB = OverTime_Binary * `Work Life Balance`,\n    OT_x_Distance = OverTime_Binary * `Distance From Home`,\n    OT_x_YearsAtCompany = OverTime_Binary * `Years At Company`\n  )\n\n# Fit logistic regression with interactions\nlogit_q1 &lt;- glm(\n  Attrition_Binary ~ OverTime_Binary + `Distance From Home` + `Work Life Balance` + \n    `Years At Company` + OT_x_WLB + OT_x_Distance + OT_x_YearsAtCompany,\n  data = hr_data,\n  family = binomial(link = \"logit\")\n)\n\nsummary(logit_q1)\n\n# Odds ratios\nexp(coef(logit_q1))\nexp(confint(logit_q1))"
  },
  {
    "objectID": "projectcode.html#random-forest-model",
    "href": "projectcode.html#random-forest-model",
    "title": "Project Code",
    "section": "4.3 Random Forest Model",
    "text": "4.3 Random Forest Model\n\n# Fit Random Forest\nrf_model &lt;- randomForest(\n  factor(Attrition_Binary) ~ OverTime_Binary + DistanceFromHome + WorkLifeBalance + YearsAtCompany,\n  data = train_data,\n  ntree = 500,\n  mtry = 2,\n  classwt = c(1, 3),\n  importance = TRUE\n)\n\nprint(rf_model)\n\n# Variable importance\nimportance(rf_model)\nvarImpPlot(rf_model)\n\n# Predictions\npred_prob_rf &lt;- predict(rf_model, test_data, type = \"prob\")[, 2]\nroc_rf &lt;- roc(test_data$Attrition_Binary, pred_prob_rf)\ncat(\"Random Forest AUC:\", auc(roc_rf), \"\\n\")\n\n# ROC comparison\nplot(roc_dt, col = \"blue\", main = \"ROC Curves - Q1 Models\")\nplot(roc_rf, col = \"red\", add = TRUE)\nlegend(\"bottomright\", c(\"Decision Tree\", \"Random Forest\"), col = c(\"blue\", \"red\"), lwd = 2)"
  },
  {
    "objectID": "projectcode.html#weighted-logistic-regression",
    "href": "projectcode.html#weighted-logistic-regression",
    "title": "Project Code",
    "section": "5.1 Weighted Logistic Regression",
    "text": "5.1 Weighted Logistic Regression\n\n# Create weights\nweights &lt;- ifelse(hr_data$Attrition_Binary == 1, weight_pos, weight_neg)\n\n# Fit weighted logistic regression\nlogit_q2 &lt;- glm(\n  Attrition_Binary ~ `Years Since Last Promotion` + `Years In Current Role` +\n    `Monthly Income` + `Percent Salary Hike` + `Job Level`,\n  data = hr_data,\n  family = binomial(),\n  weights = weights\n)\n\nsummary(logit_q2)\n\n# Odds ratios\nexp(coef(logit_q2))\nexp(confint(logit_q2))"
  },
  {
    "objectID": "projectcode.html#lasso-variable-selection",
    "href": "projectcode.html#lasso-variable-selection",
    "title": "Project Code",
    "section": "5.2 LASSO Variable Selection",
    "text": "5.2 LASSO Variable Selection\n\n# Prepare feature matrix\nlasso_vars &lt;- c(\"Years Since Last Promotion\", \"Years In Current Role\", \"Monthly Income\",\n                \"Percent Salary Hike\", \"Job Level\", \"Age\", \"Total Working Years\",\n                \"Years At Company\", \"Years With Curr Manager\", \"Distance From Home\",\n                \"Job Satisfaction\", \"Environment Satisfaction\", \"Work Life Balance\",\n                \"OverTime_Binary\", \"Num Companies Worked\", \"Stock Option Level\")\n\nX_lasso &lt;- as.matrix(hr_data[, lasso_vars])\ny_lasso &lt;- hr_data$Attrition_Binary\n\n# Cross-validated LASSO\ncv_lasso &lt;- cv.glmnet(X_lasso, y_lasso, family = \"binomial\", alpha = 1, nfolds = 10)\n\n# Plot CV\nplot(cv_lasso)\n\n# Optimal lambda\ncat(\"Optimal Lambda:\", cv_lasso$lambda.min, \"\\n\")\n\n# Coefficients\nlasso_coefs &lt;- coef(cv_lasso, s = \"lambda.min\")\nprint(lasso_coefs)"
  },
  {
    "objectID": "projectcode.html#roc-auc-and-threshold-analysis",
    "href": "projectcode.html#roc-auc-and-threshold-analysis",
    "title": "Project Code",
    "section": "5.3 ROC-AUC and Threshold Analysis",
    "text": "5.3 ROC-AUC and Threshold Analysis\n\n# Predictions\npred_probs_q2 &lt;- predict(logit_q2, type = \"response\")\nroc_q2 &lt;- roc(hr_data$Attrition_Binary, pred_probs_q2)\n\n# Optimal threshold (Youden's J)\ncoords_best &lt;- coords(roc_q2, \"best\", ret = c(\"threshold\", \"sensitivity\", \"specificity\"))\ncat(\"Optimal Threshold:\", coords_best$threshold, \"\\n\")\ncat(\"Sensitivity:\", coords_best$sensitivity, \"\\n\")\ncat(\"Specificity:\", coords_best$specificity, \"\\n\")\n\n# ROC plot\nplot(roc_q2, main = \"ROC Curve - Career Stagnation Model\")\npoints(coords_best$specificity, coords_best$sensitivity, pch = 19, col = \"red\", cex = 2)\n\n# Classification at different thresholds\nfor (thresh in c(0.1, 0.2, 0.3, 0.4, 0.5, coords_best$threshold)) {\n  pred &lt;- ifelse(pred_probs_q2 &gt;= thresh, 1, 0)\n  sens &lt;- mean(pred[hr_data$Attrition_Binary == 1] == 1)\n  spec &lt;- mean(pred[hr_data$Attrition_Binary == 0] == 0)\n  acc &lt;- mean(pred == hr_data$Attrition_Binary)\n  cat(sprintf(\"Threshold %.3f: Sens=%.3f, Spec=%.3f, Acc=%.3f\\n\", thresh, sens, spec, acc))\n}"
  },
  {
    "objectID": "projectcode.html#vif-analysis",
    "href": "projectcode.html#vif-analysis",
    "title": "Project Code",
    "section": "6.1 VIF Analysis",
    "text": "6.1 VIF Analysis\n\n# VIF model\nvif_model &lt;- lm(Attrition_Binary ~ `Job Satisfaction` + `Environment Satisfaction` +\n                  `Relationship Satisfaction` + `Work Life Balance` + \n                  `Job Involvement` + `Monthly Income` + Age,\n                data = hr_data)\n\nvif(vif_model)"
  },
  {
    "objectID": "projectcode.html#stratified-logistic-regression",
    "href": "projectcode.html#stratified-logistic-regression",
    "title": "Project Code",
    "section": "6.2 Stratified Logistic Regression",
    "text": "6.2 Stratified Logistic Regression\n\n# Fit models for each department\ndepartments &lt;- c(\"Sales\", \"R&D\", \"HR\")\n\nfor (dept in departments) {\n  cat(\"\\n========================================\\n\")\n  cat(\"DEPARTMENT:\", dept, \"\\n\")\n  cat(\"========================================\\n\")\n  \n  df_dept &lt;- hr_data %&gt;% filter(Department == dept)\n  \n  cat(\"Sample Size:\", nrow(df_dept), \"\\n\")\n  cat(\"Attrition Rate:\", round(mean(df_dept$Attrition_Binary) * 100, 1), \"%\\n\")\n  \n  model_dept &lt;- glm(\n    Attrition_Binary ~ `Job Satisfaction` + `Environment Satisfaction` + `Relationship Satisfaction`,\n    data = df_dept,\n    family = binomial()\n  )\n  \n  print(summary(model_dept))\n  \n  cat(\"\\nOdds Ratios:\\n\")\n  print(exp(coef(model_dept)))\n  \n  # AUC\n  pred_probs &lt;- predict(model_dept, type = \"response\")\n  roc_dept &lt;- roc(df_dept$Attrition_Binary, pred_probs, quiet = TRUE)\n  cat(\"\\nAUC:\", round(auc(roc_dept), 3), \"\\n\")\n}"
  }
]